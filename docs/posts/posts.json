[
  {
    "path": "posts/2021-10-24-3dmap/",
    "title": "Visualizing Water: Interactive 3D Map of River Basins (draft)",
    "description": "Part 3: how to represent water flux over 3D maps of river basins using WebGL.",
    "author": [
      {
        "name": "Melanie BACOU",
        "url": "https://linkedin/in/mbacou"
      }
    ],
    "date": "2021-11-07",
    "categories": [
      "draft",
      "imwi",
      "hydrology"
    ],
    "contents": "\n\nContents\nWebGL: Sample Scene Processing with Rayshader\nData Acquisition\nScene Rendering\n\nWebGL: Full Scene with Rayshader\nData Acquisition\nScene Rendering\n\n3D Processing with Three.js\n\nThis notebook is Part 3 of an exploration to visualize results of hydrologic models. In Part 1 we built custom HTML widgets using D3.js, and in Part 2 we looked at rendering water fluxes using Sankey diagrams. Here we test multiple libraries to generate hillshade (3D) views of river basins and water infrastructure, in particular we want to compare Three.js and WebGL implementations.\nAside from rendering topography and water streams in 3D (and potentially other covariate layers), our objective is to overlay custom labels to illustrate the water cycle.\nAnother objective is to provide basin and sub-basin statistics, starting with precipitation, ET, soil moisture, and adding other covariates, such as population, land use allocation, and crop allocation.\nSome inspiration below:\nTyler Morgan Tutorial: Adding OSM Data to Rayshader Maps\nFlood depth on 3D terrain\nProcedural-gl examples\nCesium platform for 3D Geospatial\nNASA Web WorldWind\nWebGL with Google Maps API on how to construct and render 3D scenes with WebGL.\n\n\nShow code\n\nlist.files(\"./fig\", full.names=TRUE)[c(2,7)] %>%\n  knitr::include_graphics()\n\n\n\n\nWebGL: Sample Scene Processing with Rayshader1\nData Acquisition\nWe’ll experiment with a smaller sample scene of the Selingue Dam in the Niger River basin.\n\n\nbasin <- shapefile(\"~/Projects/WADashboard/shared/mli/srtm/mli_basin.shp\")\nzoi <- shapefile(\"~/Projects/WADashboard/shared/mli/srtm/zoi.shp\")\next <- extent(zoi)\ncenter <- coordinates(zoi)\n\n# Get CGIAR SRTM DEM at 90m\nsrtm <- getData(\"SRTM\", lon=center[,1], lat=center[,2], path=\"_data\") %>%\n  crop(zoi) %>%\n  mask(zoi)\nsrtm\n\n\nclass      : RasterLayer \ndimensions : 838, 973, 815374  (nrow, ncol, ncell)\nresolution : 0.0008333333, 0.0008333333  (x, y)\nextent     : -8.6725, -7.861667, 11.06917, 11.7675  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      : srtm_35_10 \nvalues     : 326, 476  (min, max)\n\n# Satellite basemaps\nbmap <- maptiles::get_tiles(terra::ext(zoi), \"Esri.WorldImagery\", zoom=10) %>%\n  stack() %>%\n  crop(zoi) %>%\n  mask(zoi)\n\n\n\nThe basin covers a large area, so we would need 8 SRTM tiles, but 1 is enough for a proof of concept. Next we’ll get a satellite basemap.\n\n\nplot(terra::vect(basin), col=pal[2], border=pal[1], lwd=2,\n  main=\"Niger River Basin (Mali)\")\nplot(zoi, lty=3, col=alpha(pal[\"red\"], .6), border=pal[\"red\"], lwd=2, add=T)\ntext(-8, 10.5, \"Selingue Dam\\n(Mali)\", col=pal[\"red\"], cex=.7, font=2)\ngrid()\n\nplot(terra::ext(zoi), \n  main=\"Selingue Dam (Mali) - ESRI World Imagery\")\nplotRGB(bmap, add=T)\ngrid(col=\"white\")\n\nplot(terra::rast(srtm),\n  main=\"Selingue Dam (Mali) - SRTM 90m\")\ngrid(col=\"white\")\n\n\n\n\nScene Rendering\nNext we convert the 2 rasters to a matrix format that’s compatible with Rayshader hillshading and raytracing algorithms.\n\n\nShow code\n\n# Convert rasters to rayshader matrix format\nsrtm_array <- raster_to_matrix(srtm)\n\n# Convert sat basemap to matrix (test)\nr <- raster_to_matrix(bmap$red)\ng <- raster_to_matrix(bmap$green)\nb <- raster_to_matrix(bmap$blue)\n\nbmap_array <- array(0, dim=c(nrow(r), ncol(r), 3))\nbmap_array[,,1] <- r/255\nbmap_array[,,2] <- g/255\nbmap_array[,,3] <- b/255\n\nbmap_array %>%\n  aperm(c(2,1,3)) %>%\n  # Stretch contrast\n  rescale(to=c(0,1)) -> bmap_array\n\n\n\n2D view of the generated basemap with satellite image overlay.\n\n\nsrtm_water <- srtm_array\nsrtm_water[srtm_water < 353] <- 0\n\nbase_map_sat <- srtm_array %>%\n  height_shade() %>%\n  add_overlay(bmap_array) %>%\n  add_shadow(ray_shade(srtm_array, zscale=90)) %>%\n  add_water(detect_water(srtm_water), color=alpha(pal[\"blue\"], 0.4))\n\nplot_map(base_map_sat)\n\n\n\n\nFigure 1: Hillshaded Basemap of Selingue Dam (Niger River basin)\n\n\n\nThat doesn’t look very clear, so instead we’ll create a basemap, not using the satellite image but a built-in texture.\n\n\nbase_map <- srtm_array %>% \n  height_shade() %>% \n  add_overlay(sphere_shade(srtm_array, texture=\"desert\", \n    zscale=4, colorintensity=5), alphalayer=0.5) %>%\n  add_shadow(lamb_shade(srtm_array, zscale=6), 0) %>%\n  add_shadow(ambient_shade(srtm_array), 0) %>%\n  add_shadow(texture_shade(srtm_array, detail=8/10, contrast=9, brightness=11), 0.1) %>%\n  add_water(detect_water(srtm_water), color=alpha(pal[\"blue\"], 0.4))\n\nsaveRDS(base_map, \"./_data/base_map.rds\")\n\n\n\n\n\nShow code\n\nbase_map <- readRDS(\"./_data/base_map.rds\")\nplot_map(base_map)\n\n\n\n\nFigure 2: Hillshaded Basemap of Selingue Dam\n\n\n\nLooks better, so let’s acquire and overlay spatial features from OSM. Note that water-related features for Mali are scarcely available from OSM, but most waterways are recorded.\n\n\nosm_roads <- opq(bbox(zoi)) %>% \n  add_osm_feature(\"highway\") %>% \n  osmdata_sf()\n\nosm_water = opq(bbox(zoi)) %>% \n  add_osm_feature(\"water\") %>% \n  osmdata_sf()\n\nosm_waterway = opq(bbox(zoi)) %>% \n  add_osm_feature(\"waterway\") %>% \n  osmdata_sf()\n\nosm_place = opq(bbox(zoi)) %>% \n  add_osm_feature(\"place\") %>% \n  osmdata_sf()\n\nroad_layer <- generate_line_overlay(\n  dplyr::filter(osm_roads$osm_lines, highway %in% c(\"primary\", \"secondary\")),\n  extent=ext, srtm_array, linewidth=5, color=pal[\"black\"])\n\nwater_layer <- generate_line_overlay(\n  osm_waterway$osm_lines, \n  extent=ext, srtm_array, linewidth=3, color=pal[\"blue\"])\n\nplace_layer <- generate_label_overlay(\n  dplyr::filter(osm_place$osm_points, !is.na(name) & nchar(name)<10), \n  extent=ext, heightmap=srtm_array,\n  font=2, text_size=1.6, point_size=1.6, color=pal[\"black\"],\n  halo_color=\"white\", halo_expand=2, halo_blur=1, halo_alpha=.9, seed=1,\n  data_label_column=\"name\")\n\nscene <- base_map %>% \n#scene <- base_map_sat %>%   \n  add_overlay(road_layer) %>%\n  add_overlay(water_layer, alphalayer=1) %>%\n  add_overlay(place_layer)\n\nsaveRDS(scene, \"./_data/scene.rds\")\n\n\n\nFinally we’ll use WebGL to render this scene in 3D. We also test adding polygon (bar) annotations.\n\n\namb_layer <- ambient_shade(srtm_array, zscale=1/5)\n\nscene2 <- srtm_array %>% \n  height_shade() %>%\n  add_shadow(texture_shade(srtm_array, detail=8/10, contrast=9, brightness=11), 0) %>%\n  add_shadow(amb_layer, 0) %>%\n  add_overlay(road_layer) %>%\n  add_overlay(water_layer, alphalayer=1) %>%\n  add_overlay(place_layer)\n\nsaveRDS(scene2, \"./_data/scene2.rds\")\n\n\n\n\n\nShow code\n\nscene <- readRDS(\"./_data/scene.rds\")\nscene2 <- readRDS(\"./_data/scene2.rds\")\n\nscene %>% plot_3d(resize_matrix(srtm_array, 1/10), zscale=20, \n  theta=30, phi=20, fov=0, zoom=0.5,\n  family=\"Roboto Condensed\",\n  shadow=TRUE, shadowcolor=pal[\"black\"], solidcolor=pal[\"black\"])\n\n# Add polygon annotations\nxyz <- sf::read_sf(\"~/Projects/WADashboard/shared/mli/srtm/xyz.shp\")\nrender_polygons(xyz, ext, data_column_top=\"z\",\n  scale_data=1, color=alpha(pal[\"orange\"], 0.8), \n  lit=F, light_intensity=0.01, clear_previous=T)\n\nrglwidget()\n\n\n\n\n\nFigure 3: Interactive 3D Scene of Selingue Dam\n\n\n\nThe generated scene (PNG image and associated JS code) is 3.5MB.\nWebGL: Full Scene with Rayshader\nFollowing the approach above, we experiment with a 3D scene for the entire Niger River basin area used in the WA+ analysis.\nData Acquisition\n\n\n# Basin boundaries from IWMI\nzoi <- shapefile(\"~/Projects/WADashboard/shared/mli/srtm/mli_basin.shp\")\next <- extent(zoi)\ncenter <- coordinates(zoi)\n\n# GAUL admin-2 boundaries\nadm <- sf::st_read(\n  \"~/Projects/WADashboard/shared/mli/srtm/mli_adm2_lines.shp\")\nplaces <- sf::st_read(\n  \"~/Projects/WADashboard/shared/mli/srtm/mli_adm2_centroids.shp\")\n\n# CGIAR SRTM DEM (upsampled)\nalt <- lapply(c(\"MLI\", \"GIN\", \"CIV\"), \n  function(x) getData(\"alt\", country=x, mask=FALSE) %>%\n    crop(zoi) %>%\n    mask(zoi)\n)\nalt <- mosaic(alt[[1]], alt[[2]], alt[[3]], fun=mean)\nalt <- mask(crop(alt, zoi), zoi)\nwriteRaster(alt, \"~/Projects/WADashboard/shared/mli/srtm/mli_alt.tif\",\n  overwrite=T)\nalt\n\n# ESA WorldCover (clipped in QGIS)\nluc <- raster(\"~/Projects/WADashboard/shared/mli/srtm/ESA WorldCover clip.tiff\")\n\n# Note that I can't find a colormap for this raster, so switching to ESA CCI instead\nluc <- raster(\"~/Projects/WADashboard/shared/mli/srtm/mli_esa_cci_300m.tif\")\n\n# And its colormap\npal.luc <- fread(\"~/Maps/ESA/ESA CCI Colormap.txt\")\nsetnames(pal.luc, c(\"value\", \"R\", \"G\", \"B\", \"A\", \"label\"))\npal.luc[, hex := rgb(R, G, B, maxColorValue=255)]\n\n# We'll use GloRIC v1.0 stream network instead of OSM\n# Features are filtered to 'Class_hydr > 12'\ngloric <- sf::st_read(\"~/Projects/WADashboard/shared/mli/srtm/mli_gloric_filtered.shp\")\n\n# Country labels\nosm_place <- opq(bbox(zoi)) %>% \n  add_osm_feature(\"place\", \"country\") %>% \n  osmdata_sf()\n\nsave(zoi, ext, adm, places, alt, luc, pal.luc, gloric, osm_place,\n  file=\"./_data/osm.RData\")\n\n\n\n\n\nload(\"./_data/osm.RData\")\n\nplot(terra::rast(alt),\n  main=\"Niger River Basin (Mali) - SRTM 1km\")\nplot(adm, lty=3, col=pal[\"black\"], lwd=1, add=T)\nplot(gloric, col=pal[\"blue\"], lwd=.4, add=T)\ngrid()\n\nplot(terra::rast(luc), col=pal.luc$hex, \n  breaks=pal.luc$value, legend=F,\n  main=\"Niger River Basin (Mali) - ESA CCI 300m\")\nplot(adm, lty=3, col=pal[\"black\"], lwd=1, add=T)\ngrid()\n\n\n\n\nScene Rendering\nSame configuration as above.\n\n\nShow code\n\n# Convert rasters to rayshader matrix format\nsrtm_array <- raster_to_matrix(alt)\n\nbmap <- RGB(luc, col=pal.luc$hex, breaks=c(0,pal.luc$value))\n\n# Convert land cover raster to matrix (test)\nr <- raster_to_matrix(bmap$red)\ng <- raster_to_matrix(bmap$green)\nb <- raster_to_matrix(bmap$blue)\n\nbmap_array <- array(0, dim=c(nrow(r), ncol(r), 3))\nbmap_array[,,1] <- r/255\nbmap_array[,,2] <- g/255\nbmap_array[,,3] <- b/255\n\nbmap_array <- bmap_array %>%\n  aperm(c(2,1,3)) %>%\n  # Stretch contrast\n  rescale(to=c(0,1))\n\n\n\n2D view of the generated basemap with land cover overlay.\n\n\nbase_map_luc <- srtm_array %>%\n  height_shade() %>%\n  add_overlay(bmap_array) %>%\n  add_shadow(lamb_shade(srtm_array, zscale=6), 0.5) %>%\n  add_shadow(ambient_shade(srtm_array), 0.5)\n\nsaveRDS(base_map_luc, \"./_data/base_map_luc_basin.rds\")\n\n\n\n\n\nShow code\n\nbase_map_luc <- readRDS(\"./_data/base_map_luc_basin.rds\")\nplot_map(base_map_luc)\n\n\n\n\nFigure 4: Hillshaded Land Cover - Niger River Basin\n\n\n\nThe choice of hillshading parameters below might need tweaking.\n\n\nbase_map <- srtm_array %>%\n  sphere_shade(texture=\"desert\") %>%\n  #add_shadow(ray_shade(srtm_array, zscale=50))\n  add_shadow(lamb_shade(srtm_array, zscale=6), 0.5) %>%\n  # This step takes up to 5min on 4 cores / 8GB\n  add_shadow(ambient_shade(srtm_array), 0.5)\n\nsaveRDS(base_map, \"./_data/base_map_basin.rds\")\n\n\n\n2D view of the generated basemap with simple texture overlay.\n\n\nShow code\n\nbase_map <- readRDS(\"./_data/base_map_basin.rds\")\nplot_map(base_map)\n\n\n\n\nFigure 5: Hillshaded Basemap - Niger River Basin\n\n\n\nAs above, we choose to overlay place names, waterways, and level-2 administrative boundaries.\n\n\nadmin_layer <- generate_line_overlay(adm,\n  extent=ext, srtm_array, linewidth=4, lty=1, color=\"white\")\n\nadmin_layer2 <- generate_line_overlay(adm,\n  extent=ext, srtm_array, linewidth=2, lty=1, color=pal[\"black\"], \n  offset=c(0, 0.03))\n\nwater_layer <- generate_line_overlay(gloric, \n  extent=ext, srtm_array, linewidth=6, color=pal[\"light-blue\"],\n  data_column_width=\"Class_hydr\")\n\nplace_layer <- generate_label_overlay(places,\n  extent=ext, heightmap=srtm_array,\n  font=2, text_size=1.6, point_size=0, color=\"white\",\n  halo_color=pal[\"black\"], halo_expand=2, halo_blur=2, halo_alpha=.6,\n  seed=1, data_label_column=\"ADM2_NAME\")\n\ncountry_layer <- generate_label_overlay(osm_place$osm_points,\n  extent=ext, heightmap=srtm_array, offset=c(0.1, -0.5),\n  font=3, text_size=3, point_size=0, color=pal[\"light\"],\n  halo_color=pal[\"black\"], halo_expand=4, halo_blur=4, halo_alpha=.6,\n  halo_offset=c(0.1, -0.5),\n  seed=1, data_label_column=\"name\")\n\nscene <- base_map %>%\n  add_overlay(admin_layer) %>%\n  add_overlay(water_layer) %>%\n  add_overlay(place_layer)\n\nplot_map(scene)\nsaveRDS(scene, \"./_data/scene_basin.rds\")\n\nscene_luc <- base_map_luc %>% \n  add_overlay(admin_layer2, alphalayer=.8) %>%\n  add_overlay(admin_layer, alphalayer=.9) %>%\n  add_overlay(country_layer) %>%\n  add_overlay(water_layer) %>%\n  add_overlay(place_layer)\n\nplot_map(scene_luc)\nsaveRDS(scene_luc, \"./_data/scene_luc_basin.rds\")\n\n\n\nFinally we’ll use WebGL to render these scenes in 3D.\n\n\nShow code\n\nscene <- readRDS(\"./_data/scene_basin.rds\")\nscene %>% plot_3d(resize_matrix(srtm_array, 1/5), zscale=40, \n  linewidth=0, theta=15, phi=45, fov=0, zoom=0.4, \n  family=\"Roboto Condensed\",\n  shadow=TRUE, shadowcolor=pal[\"black\"], solidcolor=pal[\"black\"])\n\nrglwidget()\n\n\n\n\n\nFigure 6: Interactive 3D Scene of Niger River Basin\n\n\n\nShow code\n\nrgl.close()\n\n\n\n\n\nShow code\n\nscene_luc <- readRDS(\"./_data/scene_luc_basin.rds\")\nscene_luc %>% plot_3d(resize_matrix(srtm_array, 1/5), zscale=40, \n  linewidth=0, theta=15, phi=45, fov=0, zoom=0.4, \n  family=\"Roboto Condensed\",\n  shadow=TRUE, shadowcolor=pal[\"black\"], solidcolor=pal[\"black\"])\n\nrglwidget()\n\n\n\n\n\nFigure 7: Interactive 3D Scene of Niger River Basin with Land Cover Basemap\n\n\n\nShow code\n\nrgl.close()\n\n#save_3dprint(\"mli_basin.stl\", maxwidth=\"120mm\", clear=TRUE)\n#save_obj(\"mli_basin.obj\")\n\n\n\n3D Processing with Three.js\nFor comparison’s sake we build a similar scene using Three.js libraries instead of WebGL. The scene is 12 MB in size (using a low resampling rate), it was generated using the Qgis2threejs plugin. The main difference is we’re showing ESA CCI land cover classification as an image overlay instead of a texture.\nThe widget is rendered here.\nIn Part 4 we experiment with another WebGL-derived Javascript library Deck.gl and 3D rendering of terrain layers.\n\n\n\nAkagi, Minoru. 2021. “Qgis2threejs Plugin 2.4 documentation.” https://qgis2threejs.readthedocs.io/en/docs/index.html.\n\n\nFranke, Loraine, and Daniel Haehn. 2020. “Modern scientific visualizations on the web.” Informatics 7 (4). https://doi.org/10.3390/INFORMATICS7040037.\n\n\nHssaisoune, Mohammed, Lhoussaine Bouchaou, Abdelfattah Sifeddine, Ilham Bouimetarhan, and Abdelghani Chehbouni. 2020. “Moroccan Groundwater Resources and Evolution with Global Climate Changes.” Geosciences (Switzerland) 10 (2). https://doi.org/10.3390/geosciences10020081.\n\n\nLiu, Li, Deborah Silver, and Karen Bemis. 2019. “Visualizing three-dimensional ocean eddies in web browsers.” IEEE Access 7: 44734–47. https://doi.org/10.1109/ACCESS.2019.2909655.\n\n\nMarre, Alain. 2015. “Eau, Agriculture et Pauvreté dans le bassin du Niger: synthèse des résultats du BFP Niger.” Physio-Géo, no. Volume 9 (January): 21–24. https://doi.org/10.4000/physio-geo.4650.\n\n\nMcPhail, Travis. 2021. “Using New WebGL-powered Maps Features | Google Cloud Blog.” https://cloud.google.com/blog/products/maps-platform/using-new-webgl-powered-maps-features.\n\n\nMorgan, Tyler. 2021. “A Step-by-Step Guide to Making 3D Maps with Satellite Imagery in R.” https://www.tylermw.com/a-step-by-step-guide-to-making-3d-maps-with-satellite-imagery-in-r/.\n\n\nPopovs, Konrāds, Tomas Saks, and Jānis Jātnieks. 2015. “Web Based 3D Visualization of Kazu Leja Conceptual Geological Model.” Estonian Journal of Earth Sciences 64 (2): 173–88. https://doi.org/10.3176/earth.2015.25.\n\n\nhttps://www.rayshader.com/↩︎\n\n  \n    \n      Share:  \n      \n        \n      \n      \n        \n      \n    \n  \n\n\n",
    "preview": "posts/2021-10-24-3dmap/./fig/preview.png",
    "last_modified": "2023-12-13T22:24:48+00:00",
    "input_file": {},
    "preview_width": 624,
    "preview_height": 384
  },
  {
    "path": "posts/2021-11-01-deckgl/",
    "title": "Visualizing Water: 3D Rendering of River Basins (draft)",
    "description": "Part 4: how to represent water flux over 3D maps of river basins using Deck.gl.",
    "author": [
      {
        "name": "Melanie BACOU",
        "url": "https://linkedin/in/mbacou"
      }
    ],
    "date": "2021-11-07",
    "categories": [
      "draft",
      "imwi",
      "hydrology"
    ],
    "contents": "\nTesting additional 3D mapping libraries to render river basin topography.\n\n\nif(interactive()) setwd(\"_posts/2021-11-01-deckgl/\")\n\nlibrary(knitr)\nlibrary(scales)\nlibrary(stringr)\nlibrary(data.table)\nlibrary(sf)\nlibrary(deckgl)\n\nopts_chunk$set(res=220, pointsize=8)\n\n# Default color palette\npal <- readRDS(\"../../_assets/pal_iwmi.rds\")\npar(font.main=1, cex.axis=.8)\n\n# Load layers from Part 3\nload(\"../2021-10-24-3dmap/_data/osm.RData\")\n\nadm.pts <- st_centroid(adm)\nadm[, \"color\"] <- colour_ramp(\n  unname(pal[1:3]))(seq(0, 1, length=nrow(adm)))\next <- st_bbox(adm)\n\n\n\nThis implementation is derived from Deck.gl terrain demo.\nLoad terrain and satellite tilesets using R package deckgl.\n\n\nmb_token = Sys.getenv(\"MAPBOX_TOKEN\")\nmapbox_api = \"https://api.mapbox.com/v4/mapbox.%s/{z}/{x}/{y}.png?access_token=%s\"\nterrain_img = \"terrain-rgb\"\nsurface_img = \"satellite\"\n\nelev_map = list(\n  rScaler = 6553.6,\n  gScaler = 25.6,\n  bScaler = 0.1,\n  offset = -10000  \n)\n\nprops_basemap = list(\n  minZoom = 0,\n  maxZoom = 23,\n  strategy = \"no-overlap\",\n  elevationDecoder = elev_map,\n  elevationData = sprintf(mapbox_api, terrain_img, mb_token),\n  texture = sprintf(mapbox_api, surface_img, mb_token),\n  wireframe = FALSE,\n  color = c(255, 255, 255)\n)\n\nprops_admin = list(\n  getPolygon = JS(\"d => d.geometry.coordinates\"),\n  getElevation = ~ADM2_CODE/10,\n  extruded = TRUE,\n  pickable = TRUE,\n  stroked = TRUE,\n  filled = TRUE,\n  wireframe = FALSE,\n  lineWidthMinPixels = 2,\n  getLineWidth = 2,\n  getLineColor = pal[[\"light\"]],\n  getFillColor = ~alpha(color, .4),\n  lineJointRounded = TRUE,\n  material = list(ambient=0.35, diffuse=0.7, shininess=32),\n  tooltip = \"Region: {{ADM1_NAME}}<br/>District: {{ADM2_NAME}}\"  \n)\n\nprops_text = list(\n  pickable = FALSE,\n  getPosition = JS(\"d => d.geometry.coordinates\"),\n  getText = ~ADM2_NAME,\n  getColor = pal[[\"black\"]],\n  sizeMinPixels = 11,\n  sizeMaxPixels = 18,\n  getAngle = 0,\n  background = TRUE,\n  backgroundPadding = c(2, 2),\n  getBackgroundColor = pal[[\"light\"]]\n)\n\ndeckgl(\n  element_id = \"map\",\n  width = \"100%\",\n  height = \"360px\",  \n  longitude = -8,\n  latitude = 11,\n  zoom = 5,\n  bearing = 0,\n  pitch = 40,\n  maxPitch = 180,\n) %>%\n  add_layer(\"TerrainLayer\", properties=props_basemap) %>%\n  add_polygon_layer(data=adm, properties=props_admin) %>%\n  add_text_layer(data=adm.pts, properties=props_text)\n\n\n\n\nUse Shift + Click to tilt the view angle.\nUsing Mapbox experimental vector tiles below.\n\n\nprops_admin = list(\n  getPolygon = JS(\"d => d.geometry.coordinates\"),\n  getElevation = ~ADM2_CODE/10,\n  extruded = FALSE,\n  pickable = TRUE,\n  stroked = TRUE,\n  filled = TRUE,\n  wireframe = FALSE,\n  lineWidthMinPixels = 1,\n  getLineWidth = 1,\n  getLineColor = pal[[\"orange\"]],\n  getFillColor = alpha(pal[[\"orange\"]], .4),\n  lineJointRounded = TRUE,\n  material = list(ambient=0.35, diffuse=0.7, shininess=32),\n  tooltip = \"Region: {{ADM1_NAME}}<br/>District: {{ADM2_NAME}}\"  \n)\n\nprops_water = list(\n  pickable = FALSE,\n  getPath = JS(\"d => d.geometry.coordinates\"),\n  getWidth = ~rescale(Class_hydr, to=c(2,8)),\n  getColor = alpha(pal[[\"blue\"]], .8),\n  widthMinPixels = 2,\n  widthMaxPixels = 8,\n  capRounded = TRUE,\n  jointRounded = TRUE,\n  `_pathType` = \"open\"\n)\n\ndeckgl(\n  element_id = \"map2\",\n  width = \"100%\",\n  height = \"360px\",\n  longitude = -8,\n  latitude = 11,\n  zoom = 5,\n  bearing = 0,\n  pitch = 0,\n  maxPitch = 180,\n) %>%\n  add_basemap(\"https://api.maptiler.com/maps/42a84100-2300-4647-ba8f-a70afaf51946/style.json?key=JdazoF74wMMlc8Esnhmm\") %>%\n  add_polygon_layer(data=adm, properties=props_admin) %>%\n  add_path_layer(data=gloric, properties=props_water)\n\n\n\n\nUse Shift + Click to tilt the view angle.\n\n\n\n  \n    \n      Share:  \n      \n        \n      \n      \n        \n      \n    \n  \n\n\n",
    "preview": "posts/2021-11-01-deckgl/preview.png",
    "last_modified": "2023-12-13T22:24:48+00:00",
    "input_file": {},
    "preview_width": 401,
    "preview_height": 360
  },
  {
    "path": "posts/2021-10-16-svg/",
    "title": "Visualizing Water: Interactive SVG with D3.js (draft)",
    "description": "Part 1: add interactivity to IWMI's printable WA+ sheets.",
    "author": [
      {
        "name": "Melanie BACOU",
        "url": "https://linkedin/in/mbacou"
      }
    ],
    "date": "2021-11-01",
    "categories": [
      "draft",
      "imwi",
      "hydrology"
    ],
    "contents": "\n\nContents\nData Preparation\nInteractive Sheets\nOptimized SVG\nHTML Widget\n\n\n\n\nShow code\n\nif(interactive()) setwd(\"./_posts/2021-10-16-svg\")\n\nlibrary(rmarkdown)\nlibrary(jsonlite)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(stringr)\nlibrary(data.table)\nlibrary(r2d3)\nlibrary(crosstalk)\n\n# IMWI color palette\ntmp <- fread(\"../../_assets/IWMI.gpl\", skip=4, header=F)\npal <- grDevices::rgb(tmp[, .(V1, V2, V3)], maxColorValue=255)\nnames(pal) <- tmp[, V4]\nsaveRDS(pal, \"../../_assets/pal_iwmi.rds\")\n\n# Default plot theme\noptions(ggplot2.discrete.color=pal)\ntheme_mb <- function(\n  base_size = 8,\n  base_family = \"Roboto Condensed\",\n  base_fill = pal[\"light\"], ...) theme_minimal(base_size, base_family) +\n  theme(\n    panel.background = element_rect(fill=base_fill, color=NA),\n    plot.background = element_rect(fill=\"transparent\", color=NA),\n    panel.grid = element_line(color=\"white\"),\n    legend.box.background = element_rect(fill=\"transparent\", color=NA),\n    text = element_text(color=pal[\"black\"], lineheight=.8),\n    strip.text = element_text(face=\"bold\", hjust=0, size=base_size),\n    legend.position = \"top\",\n    legend.justification = c(\"right\", \"top\"),\n    legend.key.height = unit(.8, \"line\")\n  ) + theme(...)\n\n\n\nThis notebook is to explore multiple visualization schemes for hydrologic model simulations. It’s broken down into 3 parts:\nInteractive SVG (this page): add user interactivity to existing SVG sheets (or simplified) designs using low-level D3.js library\nFlow diagrams: reshape WA+ model output to create interactive Sankey diagrams with Highcharts.js\nInteractive 3D timelapse of river basins: create a 3D map of basin landscape with SVG annotation layers (arrows, etc.)\nThe D3.js approach is the more flexible but also the more “tedious” to implement. Other approaches will be developed in separate notebooks.\nData Preparation\nTo validate the different approaches we use sample output datasets provided by Naga Valpuri (IWMI) for Mali (Niger river basin) and Kenya (Mara river basin). All hydrologic models are written in Python and version controlled to GitHub (e.g. Mali notebooks).\n\n\nShow code\n\ndata <- list(\n  ken = \"~/Projects/2021-iwmi/data/ken/hydroloop_results/csv\",\n  mli = \"~/Projects/2021-iwmi/data/mli/csv_km3\"\n) %>%\n  lapply(list.files, pattern=\"*.csv\", recursive=TRUE, full.names=TRUE) %>%\n  lapply(data.table) %>%\n  rbindlist(idcol=\"iso3\", use.names=TRUE, fill=TRUE) %>%\n  setnames(\"V1\", \"path\")\n\ndata[, \n  file := basename(path)\n][, `:=`(\n  year = str_extract(file, \"_[0-9]{4}\") %>% str_sub(2,5) %>% as.integer(),\n  month = str_extract(file, \"[0-9]{4}_[0-9]{1,2}\") %>% str_sub(6,7) %>% as.integer(),\n  sheet = str_extract(tolower(file), \"sheet[0-9]{1}\") \n)] %>% setorder(iso3, year, month, na.last=TRUE)\n\ndata[iso3==\"ken\", .(iso3, file, sheet, year, month)] %>% \n  paged_table()\n\n\n\n\n\n\n\nShow code\n\ndata[iso3==\"mli\", .(iso3, file, sheet, year, month)] %>% \n  paged_table()\n\n\n\n\n\nIn particular we have yearly model steps for Mali and monthly steps for Kenya that are further aggregated to yearly time spans (by variable), as well as monthly time-series. In Mali only Sheet #1 was produced (Resource Base), but the Kenya analysis includes output variables for all 6 hydro sheets.\nLet’s load a sample model output for Kenya for the year 2017.\n\n\nShow code\n\nf <- \"sheet1_2017.csv\"\nken <- data[iso3==\"ken\" & file==f][1, fread(path)]\nken %>% paged_table()\n\n\n\n\n\nThis file lists 34 output variables grouped into CLASS and SUBCLASS. Units are in km³/year. This categorical data can be represented in a Sankey diagram but not very useful as-is (see next section for more work on this).\n\n\nShow code\n\nlibrary(ggalluvial)\n  \nggplot(ken, \n  aes(axis1=CLASS, axis2=abbreviate(SUBCLASS), axis3=abbreviate(VARIABLE), y=VALUE)) +\n  geom_alluvium(aes(fill=CLASS), width=1/4, alpha=.7, color=\"white\") +\n  geom_stratum(width=1/4) +\n  geom_text(stat=\"stratum\", aes(label=after_stat(stratum)), angle=90, size=2.2) +\n  scale_x_discrete(limits=c(\"class\", \"subclass\", \"variable\")) +\n  labs(y=NULL, fill=NULL) +\n  scale_fill_manual(values=unname(pal)) +\n  theme_mb(\n    panel.grid=element_blank(),\n    axis.text=element_text(face=\"bold\"))\n\n\n\n\nAnd monthly time-series of Incremental ET by land-use classes:\n\n\nShow code\n\nf <- \"sheet1_basin_etincr_monthly.csv\"\nken.ts <- data[iso3==\"ken\" & file==f][1, fread(path)]\nken.ts %>% paged_table()\n\n\n\n\n\nWe’ll gather all the yearly budgets for now into a long table, and simply visualize the time-series.\n\n\nShow code\n\nf <- data[sheet==\"sheet1\" & is.na(month) & !is.na(year)]\n\ndata <- lapply(1:nrow(f), function(x) \n  fread(f[x, path])[, `:=`(\n    iso3 = f[x, iso3],\n    sheet = f[x, sheet],\n    year = f[x, year]\n  )]) %>% rbindlist()\n\nfwrite(data, \"./data/data.csv\")\n\nggplot(data[VALUE>0 & SUBCLASS %like% \"ET\"], \n  aes(year, VALUE, color=paste(SUBCLASS, VARIABLE, sep=\" \"))) +\n  geom_line(size=1) +\n  facet_wrap(~toupper(iso3), scales=\"free\") +\n  labs(x=NULL, y=NULL, title=\"Yearly ET Budgets (kg/m³)\", color=NULL) +\n  scale_color_manual(values=unname(pal)) +\n  guides(color=guide_legend(ncol=3)) +\n  theme_mb()\n\n\n\n\nWe pass this yearly dataset to the client (web browser) as a JSON array named data. We also pass a default color palette pal (declared above) for convenience.\n\n\nShow code\n\ncat(\n  sprintf(\"\n  <script> \n  var data = %s;\n  var pal = %s;\n  <\/script>\", toJSON(data[iso3==\"ken\" & year==2017]), toJSON(pal)))\n\n\n\nInteractive Sheets\nWe work off the existing SVG designs, using D3.js constructs to add data binding and interactions. An important drawback of this approach is that each SVG element (rectangle, arrow, text, etc.) is tied to a data variable, so any change in the underlying data schema (esp. renaming of output variables) would require to manually edit the corresponding SVG template (using a text or vector graphic editor).\nThere are multiple SVG templates provided in the Kenya code repository (under ./scripts/WAsheets/template/svg). They are shown below.\n\n\nShow code\n\nlist.files(\"./svg\", pattern=\"*.svg\", full.names=TRUE)[-c(1:3,7,9)] %>%\n  knitr::include_graphics()\n\n\n\n\nThese sheets incorporate a quantity of domain-specific knowledge, they are used to both teach and communicate about the WA+ modeling approach and simulation results. The PDF documents are produced in the final step of the analysis, typically after the water accounts have been aggregated to a seasonal or yearly time span. The process is somewhat (but not entirely) automated, e.g. the analyst can decide to show or hide elements.\nNote that the original templates were created in Inkscape with SVG 1.1 specifications. They are professional printable designs and not optimized for rendering in a browser, so we start by testing whether we can interact and modify these designs using D3. We focus on the Resource Base sheet first.\n\nNote: Inkscape provides multiple templating utilities to “merge” SVG files (with template fields declared in the form %VAR_name% with CSV data in order to batch generate PNG or PDF documents. That system is not limited to merging text labels, colors and sizes can also be read in from an external CSV source1.\n\nBelow we load the sheet and proceed to map each box height/width and label to an output variable. We also create a dummy SVG barchart widget to make sure that data is read in and rendered in the browser as we expect.\nAnd we need to import D3.js as an external dependency in this notebook:\n\n\n# Import D3.js lib\nhtmltools::tags$script(src=\"https://cdn.jsdelivr.net/npm/d3@6\")\n\n\n\n\nClick to render a dummy SVG widget using the sample Kenya data for 2017 (to make sure libraries are loaded).\n\n\n\n\n\nDummy Widget\n\n\n\n\n// Keep only non-null variables\nvar dd = data.filter((d) => (d.VALUE !== 0));\n\nfunction fun_barchart(data=dd, el=\"#d3ex1\") {\n\n  d3.select(el).selectAll(\"svg\").remove();\n\n  var width = $(el).width() - 10;\n  var box = 0.6 * width/18;\n  var height = box * 21;\n  \n  var svg = d3.select(el)\n    .append(\"svg\")\n    .attr(\"viewBox\", [0, 0, width, height])\n    .append(\"g\")\n      .attr(\"transform\", \"translate(10, 10)\");  \n    \n  // Add X axis \n  var x = d3.scaleLinear()\n    .domain([0, 14])\n    .range([0, width]);\n  \n  svg\n    .selectAll(\"mybar\")\n    .data(data)\n    .enter()\n    .append(\"rect\")\n    .attr(\"x\", d => x(Math.min(0, d.VALUE)) )\n    .attr(\"y\", (_, i) => (i * (box+5)+5) )\n    .attr(\"width\", d => 0 )\n    .attr(\"height\", box)\n    .attr(\"fill\", pal[1])\n    .on(\"mouseover\", handleMouseOver)\n    .on(\"mouseout\", handleMouseOut);\n    \nsvg.selectAll(\"mybar\")\n    .data(data)\n    .enter()\n    .append(\"text\")\n    .attr(\"x\", d => x(0)+10)\n    .attr(\"y\", (_, i) => (i * (box+5) + box)  )\n    .style(\"font-size\", box*0.6 + \"px\")\n    .attr(\"text-anchor\", \"start\")\n    .text(d => (d.VALUE.toFixed(2) + \" km³/year\"));\n    \n  svg\n    .append(\"g\")\n    .selectAll(\"text\")\n    .data(data)\n    .enter()\n    .append(\"text\")\n    .attr(\"x\", width-20)\n    .attr(\"y\", (_, i) => (i * (box+5) + box) )\n    .style(\"font-size\", box*.6+\"px\")\n    .attr(\"text-anchor\", \"end\")\n    .text(d => (d.SUBCLASS + \" - \" + d.VARIABLE));\n    \n  // Animation\n  svg.selectAll(\"rect\")\n    .transition()\n    .duration(800)\n    .attr(\"width\", d => x(Math.abs(d.VALUE)))\n    .delay((d,i) => i*100);\n};\n\n// Test interactions\nfunction handleMouseOver(d, i) {\n   d3.select(this)\n   .attr(\"fill-opacity\", .5);\n};\n\nfunction handleMouseOut(d, i) {\n  d3.select(this)\n  .attr(\"fill-opacity\", 1);\n};\n\nD3 is incredibly wordy, but then again it’s flexible! Then we load the original SVG design and progressively add visual effects and data bindings.\n\n\n\n\n\nChange Text Color\n\n\nChange Fill Color\n\n\nShow Groups\n\n\nReset Widget\n\n\n\n\nvar hw = $(\"#d3ex2\").width();\nvar div = d3.select(\"#d3ex2\");\nvar svg = div\n  .append(\"svg\")\n  .attr(\"viewBox\", [0, 0, hw, hw*0.8])\n  .insert(\"svg:g\")\n  .attr(\"class\", \"d3ex2\");  \n\nfunction fun_reset(src=\"./svg/sheet_1.svg\", el=\"d3ex2\") {\n  var s = d3.select(\".\" + el);\n  s.selectAll(\"svg\").remove();\n\n  // Append external design\n  d3.xml(src)\n    .then(d => {\n    s.node().append(d.documentElement);\n    d3.select(\".\" + el)\n      .selectAll(\"rect\")\n        .on(\"mouseover\", handleMouseOver)\n        .on(\"mouseout\", handleMouseOut); \n    });\n};\n\nfun_reset();\n\nNow that we have the SVG DOM loaded, we can do silly things, like change the text color or highlight some elements. We can also list and return object attributes, which we’ll use later to bind visual elements to the underlying data.\n\n\nd3.selection.prototype.move = function(x, y) {\n  this\n    .transition()\n    .duration(800)\n    .attr(\"transform\", \"translate(\" + x + \",\" + y + \")\");\n  return this;\n};\n\nfunction fun_color(el=\"d3ex2\") {\n  d3.select(\".\" + el)\n  .select(\"svg\")\n  .selectAll(\"text\")\n    .style(\"fill\", \"white\");\n    \n  d3.select(\".\" + el)\n  .select(\"svg\")    \n  .selectAll(\"text[class=data]\")\n    .style(\"fill\", pal[5])\n    .attr(\"stroke\", pal[5])\n    .transition()\n    .duration(800)\n    .attr(\"transform\", \"translate(2,2)\")\n    .transition()\n    .duration(800)    \n    .attr(\"transform\", \"translate(0,0)\");\n };\n \nfunction fun_fill(el=\"d3ex2\") {\n  d3.select(\".\" + el)\n  .selectAll(\"path\")\n    .style(\"fill\", pal[0])\n    .attr(\"fill\", pal[0]);\n };\n \nfunction fun_group(el=\"d3ex2\", group=\"\") {\n  var g = group==\"\" ? \"g\" : \"g[id=\" + group + \"]\";\n    d3.select(\".\" + el)\n    .select(\"svg\")\n    .selectAll(g)\n      .attr(\"stroke\", pal[7])\n      .attr(\"fill-opacity\", .4)\n      .raise()\n      .move(\n        Math.floor(Math.random() * 20),\n        Math.floor(Math.random() * 10)\n        );\n};\n\nOptimized SVG\nAt this point, we need to manually modify (simplify) the original SVG design to clean up paths and to make it easier to select and manipulate (drill through) logical layers and groups of elements. We can create a useful hierarchy in Inkscape and then re-import the modified design here.\n\nNote: make sure to remove attributes <svg width=\"\" height=\"\"> from the SVG file produced by Inkscape for the design to size properly in its DOM container.\n\n\n\n\n\n\nHighlight Data\n\n\nShow Inflows\n\n\nShow Outflows\n\n\nReset Design\n\n\n\n\nd3.select(\"#d3ex3\")\n  .append(\"svg\")\n  .attr(\"viewBox\", [0, 0, hw, hw*0.8])\n  .insert(\"svg:g\")\n  .attr(\"class\", \"d3ex3\");\n\nfun_reset(\"./svg/sheet_1_edited.svg\", \"d3ex3\");\n\nNext step is to map text labels and possible cell height to data variables.\nHTML Widget\nWhen bound with the yearly model simulation dataset assembled above, the HTML widget now behaves as follows (src: shinyapps.io).\n\n\n\nYour browser does not support iframes\n\n\n\n\n\nShow code\n// !preview r2d3 data=NULL\n\nvar pal = ['#3C8DBC','#DD4B39','#00A65A','#00C0EF','#F39C12','#0073B7',\n  '#001F3F','#39CCCC','#3D9970','#01FF70','#FF851B','#F012BE','#605CA8',\n  '#D81B60','#111111','#D2D6DE'];\n\n// Interactions\nfunction handleMouseOver(d, i) {\n   d3.select(this)\n   .attr(\"fill-opacity\", 0.5);\n}\n\nfunction handleMouseOut(d, i) {\n  d3.select(this)\n  .attr(\"fill-opacity\", 1);\n}\n\nfunction handleDataMouseOver() {\n  d3.select(this)\n  .raise()\n  .attr(\"font-size\", font_size*3);\n}\n\nfunction handleDataMouseOut() {\n  d3.select(this)\n  .attr(\"font-size\", font_size);\n}\n\n\nconst obj = svg\n  .insert(\"svg:g\")\n  .attr(\"class\", \"sheet_1\");\n\nobj.selectAll(\"svg\").remove();\n\n// Init external design\nd3.xml(\"sheet_1_edited.svg\")\n  .then(d => {\n  obj.node().append(d.documentElement);\n\n  obj\n    .selectAll(\"rect\").merge(obj.selectAll(\"path\"))\n      .on(\"mouseover\", handleMouseOver)\n      .on(\"mouseout\", handleMouseOut)\n      .on(\"click\", function() {\n        Shiny.setInputValue(\n          \"bar_clicked\", {\n            \"id\" : d3.select(this).attr(\"id\"),\n            \"value\" : d3.select(this).attr(\"value\"),\n            \"var\" : d3.select(this).attr(\"var\"),\n            \"color\" : d3.select(this).attr(\"fill\")\n            }, {priority: \"event\"}\n          );\n        //console.log(d3.select(this).attr(\"d\"));\n      });\n\n  obj\n    .selectAll(\"text[class=data]\")\n      .on(\"mouseover\", handleDataMouseOver)\n      .on(\"mouseout\", handleDataMouseOut);\n\n});\n\n\n// Rendering\nr2d3.onRender(function(data, svg, width, height, options) {\n\nvar root = svg.select(\".sheet_1\").select(\"svg\");\n\n  root\n    .selectAll(\"rect\")\n    .data(data)\n    //.attr(\"height\", d => 1000*d.value)\n    .attr(\"var\", d => d.id)\n    .attr(\"value\", d => d.value);\n\n  root\n    .selectAll(\"text[class=data]\")\n    .data(data)\n    // will need to include data mapping here\n    .attr(\"text-anchor\", \"middle\")\n    .text(d => d3.format(\"(.2f\")(d.value));\n\n});\n\nObject model for Sheet #1 is shown in the table below.\n\n\nShow code\n\nmodel <- fread(\"./app/sheet_1_schema.csv\")\nmodel[, .(id, class, subclass, variable)] %>% paged_table()\n\n\n\n\n\nNext step is to animate Sheet #2 using the same approach and include these widgets into a reusable R (and/or Python) package.\n\n\n\nAstagneau, Paul C., Guillaume Thirel, Olivier Delaigue, Joseph H. A. Guillaume, Juraj Parajka, Claudia C. Brauer, Alberto Viglione, Wouter Buytaert, and Keith J. Beven. 2021. “Technical note: Hydrology modelling R packages - A unified analysis of models and practicalities from a user perspective.” Copernicus GmbH. https://doi.org/10.5194/hess-25-3937-2021.\n\n\nCoene, John. 2021. Javascript for R. Edited by Chapman & Hall. CRC The R. https://doi.org/10.1201/9781003134046.\n\n\nDarlington, Kendon. 2021. “D3 and R, a match made in heaven. A step by step tutorial for converting… | by Kendon Darlington | Towards Data Science.” https://towardsdatascience.com/d3-and-r-a-match-made-in-heaven-ff0bf82efe9a.\n\n\nDroogers, P., Gijs Simmons, Wim Bastiaanssen, and J Hoogeveen. 2010. “Water Accounting Plus (WA+) in the Okavango River Basin.” Rome, Italy: FAO, Land; Water Division. https://www.researchgate.net/publication/282002922_Water_Accounting_Plus_WA_in_the_Okavango_River_Basin.\n\n\nGranjon, David, and John Coene. 2020. Outstanding User Interfaces with Shiny. https://unleash-shiny.rinterface.com/.\n\n\nMarre, Alain. 2015. “Eau, Agriculture et Pauvreté dans le bassin du Niger: synthèse des résultats du BFP Niger.” Physio-Géo, no. Volume 9 (January): 21–24. https://doi.org/10.4000/physio-geo.4650.\n\n\nWorld Bank. 2010. “The Zambezi River Basin A Multi-Sector Investment Opportunities Analysis.” Washington D.C, USA.: World Bank.\n\n\nFor example inkscape_merge tool.↩︎\n\n  \n    \n      Share:  \n      \n        \n      \n      \n        \n      \n    \n  \n\n\n",
    "preview": "posts/2021-10-16-svg/./svg/sheet_1_edited.svg",
    "last_modified": "2023-12-13T22:24:48+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-16-rfmerge/",
    "title": "Merge Ground and Satellite Observations with RFMerge",
    "description": "Recalibrate ERA5 hourly temperatures to CIMIS network ground observations.",
    "author": [
      {
        "name": "BACOU, Melanie",
        "url": "https://linkedin/in/mbacou"
      }
    ],
    "date": "2021-01-16",
    "categories": [
      "meteo",
      "risk modeling"
    ],
    "contents": "\nWe want to recalibrate ERA5-LAND hourly temperatures to CIMIS ground network observations to address ERA5-LAND model biases noted in California:\nBuild CIMIS time-series across OLAM portfolio extent\nBuild DEM covariate using ERA5-LAND extent and spatial resolution\nUse RFMerge procedure1 to produce calibrated hourly raster stacks over the past 10 years (limit calibration from Jan-01 to Apr-30 every year)\nThis work was initially performed for WorldCover PBC and OLAM US, redacted here to omit confidential details.\n\n\nlibrary(rmarkdown)\nlibrary(lattice)\nlibrary(raster)\nlibrary(tmap)\nlibrary(scales)\nlibrary(data.table)\nlibrary(zoo)\nlibrary(cimir)\nlibrary(sf)\nlibrary(RFmerge)\n\ndir <- \".\"\nload(file.path(dir, \"./tmp/2020-burn_olam_usa_06.RData\"))\n\n# Default color palette\npal <- readRDS(\"../../_assets/pal_iwmi.rds\")\n\nmy.settings <- list(\n  superpose.polygon=list(col=alpha(pal, .6), border=\"transparent\"),\n  strip.background=list(col=pal[\"light\"])\n)\n\n\n\nDefine zone of interest and load covariate layers.\n\n\n# Clear workspace, keep portfolio details\nload(file.path(dir, \"./tmp/2020-burn_olam_usa_04.RData\"))\nrm(list=setdiff(ls(), c(\"dir\", \"pts.dt\")))\n\npts <- SpatialPointsDataFrame(pts.dt[, .(X,Y)], data.frame(pts.dt), \n  proj4string=CRS(\"+init=epsg:4326\"))\n\nusa <- getData(\"GADM\", country=\"USA\", level=2)\n# Limit to OLAM counties\nusa <- usa[usa$NAME_2 %in% pts.dt[, unique(adm2_nm)],]\nzoi <- extent(usa)\nzoi\n# class      : Extent \n# xmin       : -121.4844 \n# xmax       : -117.6166 \n# ymin       : 34.7902 \n# ymax       : 38.07786 \n\n# Catalog hourly ERA5 tmean\nf <- list.files(file.path(dir, \"../maps/ERA5LAND/2m_temperature/hourly/usa.ca\"), \".nc\", \n  recursive=T, full.names=T)\n\n# Verify data archive\nn <- sapply(f, function(x) nlayers(brick(x, quick=T)))\nunique(n)\n# [1] 23 24  1 22\nbad <- f[names(n[n<24])]\nn <- sapply(f[bad], function(x) nlayers(brick(x, quick=T)))\ndata.table(\n  fname = basename(f[bad]),\n  nlayers = n)\n#                  fname nlayers\n# 1: daily_1981-01-01.nc      23\n# 2: daily_2020-08-01.nc       1\n# 3: daily_2020-10-01.nc      22\n# 4: daily_2020-10-02.nc      22\n# 5: daily_2020-10-03.nc      22\n# 6: daily_2020-10-15.nc      22\n\nN <- lapply(f[1:10], function(x) {\n  s = brick(x, quick=T)\n  s = setMinMax(s)\n  s = minValue(s) == maxValue(s)\n  which(s)\n})\nbad <- N[sapply(N, `!=`, integer(0))]\n\n\n\nObtain long-term weather station records from CIMIS API.\n\n\nset_key(\"27ab5faa-abbb-475e-8af1-f380862bca61\")\nitem <- \"hly-air-tmp\"\n\n# Keep all CIMIS stations inside ZOI\nobs.gis <- cimis_station()\nsetDT(obs.gis)\nobs.gis[1:3, .(ConnectDate, DisconnectDate, HmsLatitude, HmsLongitude)]\n#    ConnectDate DisconnectDate           HmsLatitude              HmsLongitude\n# 1:    6/7/1982      9/25/1988 36º48'52N / 36.814444 -119º43'54W / -119.731670\n# 2:    6/7/1982      9/25/1988 36º48'52N / 36.814444 -119º43'54W / -119.731670\n# 3:    6/7/1982      9/25/1988 36º48'52N / 36.814444 -119º43'54W / -119.731670\n\nobs.gis[, `:=`(\n  # HMS Lat/Lon to degree\n  X = unlist(tstrsplit(HmsLongitude, \" / \", fixed=T, keep=2L)),\n  Y = unlist(tstrsplit(HmsLatitude, \" / \", fixed=T, keep=2L))\n)][, `:=`(\n  X = as.numeric(X),\n  Y = as.numeric(Y)\n)][, `:=`(\n  # Cast dates\n  date_start = as.Date(ConnectDate, format=\"%m/%d/%Y\"),\n  date_end = as.Date(DisconnectDate, format=\"%m/%d/%Y\")\n)]\n\nobs.gis[1:3, .(HmsLongitude, HmsLatitude, X, Y, date_start, date_end)]\nobs.gis <- obs.gis[, .(StationNbr, Name, X, Y, date_start, date_end, IsActive)]\n\n# There are duplicated stations (?)\nobs.gis <- unique(obs.gis, by=c(\"StationNbr\", \"X\", \"Y\", \"date_start\"))\nanyDuplicated(obs.gis, by=\"StationNbr\")\n\n# Date ranges that are available\nobs.gis[, .(range(date_start), range(date_end))]\n#            V1         V2\n# 1: 1982-05-30 1985-07-23\n# 2: 2020-10-28 2050-12-31\n\nobs.gis <- SpatialPointsDataFrame(obs.gis[, .(X, Y)], data.frame(obs.gis),\n  proj4string=CRS(\"+init=epsg:4326\"))\nobs.gis <- crop(obs.gis, zoi)\n\n# Plot maps\nplot(crop(raster(r, layer=2), zoi), main=basename(f[2]))\nplot(pts, add=T, pch=\"*\")\nplot(obs.gis, add=T, col=c(\"red\", \"green\")[1+(obs.gis$IsActive==\"True\")], pch=\"x\")\n\nobs.lst <- obs.gis@data[, \"StationNbr\"]\nlength(obs.lst)\n\nobs.gis <- setDT(obs.gis@data)\n\n# API limit at 1,750 records so batch it\ndrange <- c(\"2017-01-01\", \"2017-04-30\")\nobs <- lapply(obs.lst, function(x) {\n  date_start = obs.gis[StationNbr==x, date_start]\n  date_end = obs.gis[StationNbr==x, date_end]\n  date_start = pmax(as.Date(drange[1]), date_start)\n  date_end = pmin(as.Date(drange[2]), date_end)\n  res = if(date_end >= date_start) {\n    s = seq.Date(date_start, date_end, by=\"10 days\")\n    lapply(s, function(y) {\n      t = try(cimis_data(\n        targets=as.integer(x), items=item, measure.unit=\"M\", start.date=y, end.date=y+10-1))\n      t = if(class(t)[1]==\"try-error\") NULL else setDT(t)\n      return(t)\n    })\n  } else NULL\n  return(res)\n})\n\nobs <- lapply(obs, rbindlist)\nnames(obs) <- obs.lst\nobs <- rbindlist(obs, fill=T, idcol=\"StationNbr\")\n\n# Clean up\nobs[, `:=`(\n  Name = NULL,\n  Type = NULL,\n  Owner = NULL,\n  Standard = NULL,\n  ZipCodes = NULL,\n  Item = NULL,\n  Qc = NULL,\n  Unit = NULL\n)]\n\n# Verify\nobs[StationNbr != Station, .N]\nobs[, .N, by=Scope]\nobs[, `:=`(\n  Station = NULL,\n  Scope = NULL\n)]\n\n# Tally\nobs[, .(.N, min(Date), max(Date)), keyby=.(StationNbr)]\n# => \"232\" station missing records 2160/2880\nobs[, .(.N, sum(is.na(Value)), min(Date), max(Date)), keyby=.(StationNbr)]\n24*(as.Date(drange[2])-as.Date(drange[1])+1)\n\n# Nearest to OLAM3 portfolio\nids <- c(168, 206, 145, 188, 148)\nfwrite(obs[StationNbr %in% as.character(ids)], \"./out/CIMIA_OLAM3_2017.csv\")\n\n\n\nPrepare DEM at ERA5 layers.\n\n\n# Prepare DEM at ERA5 extent and resolution\ndem1 <- getData(\"SRTM\", lon=zoi[2], lat=zoi[3])\ndem2 <- getData(\"SRTM\", lon=zoi[1], lat=zoi[4])\ndem3 <- getData(\"SRTM\", lon=zoi[2], lat=zoi[4])\ndem4 <- getData(\"SRTM\", lon=zoi[1], lat=zoi[3])\ndem <- merge(dem1, dem2, dem3, dem4, ext=zoi)\n\n\n\nFormat station time-series to Zoo wide arrays.\n\n\n# Prep station time-series, require ZOO wide format\nobs[, Time := paste(as.character(Date), Hour)\n][, c(\"Date\", \"Time\") := IDateTime(\n  as.POSIXlt(Time, format=\"%Y-%m-%d %H%M\", tz=\"America/Los_Angeles\"))]\nView(obs[c(1:30, .N)])\n# 2017-01-01 2300 => 2017-01-01 23:00\n# 2017-01-01 2400 => 2017-01-02 00:00\n# => OK\nsetorder(obs, StationNbr, Date, Time)\nobs.ts <- dcast(obs, Date+Time~StationNbr, value.var=\"Value\")\nobs.ts <- zoo(\n  obs.ts[, .SD, .SDcols=-c(1:2)], \n  order.by=obs.ts[, as.POSIXlt(paste(Date, Time, tz=\"America/Los_Angeles\"))]\n)\n\n\n\nImplement Random Forest merge algorithm.\n\n\n# Cut the series at Jan-Apr 2017 (time constraint)\ndrange <- c(\"2017-01-01\", \"2017-04-30\")\nx1 <- which(f %like% drange[1])\nx2 <- which(f %like% drange[2])\nf <- f[x1:x2]\nf[1]\n\n# Limit ERA5 covariate\nera <- brick(as.list(f))\nera <- crop(era, zoi, filename=\"./out/ERA5_2m_temperature_2017.grd\", overwrite=T)\nera <- brick(\"./out/ERA5_2m_temperature_2017.grd\")\n\n# Align DEM to ERA5\ndem <- resample(dem, era[[1]], filename=\"./out/SRTM_ERA5.grd\")\nidentical(res(dem), res(era))\nidentical(extent(dem), extent(era))\nidentical(nlayers(era), nrow(obs.ts))\n\n# ZOI require SF\nstations <- sf::st_as_sf(obs.gis, coords=c(\"X\", \"Y\"), crs=4326)\nzoi <- st_as_sfc(st_bbox(usa))\nzoi <- st_sf(data.frame(ID=1), geom=zoi)\n\n# Verify CRS\nidentical(st_crs(zoi), st_crs(era))\nidentical(st_crs(r), st_crs(era))\n\n# Reproject all to NAD_1983_California_Teale_Albers\nNAD83 <- CRS(\"+init=epsg:3310\")\nera <- projectRaster(from=era, crs=NAD83)\ndem <- projectRaster(from=dem, crs=NAD83)\nstations <- st_transform(stations, crs=3310)\npts <- spTransform(pts, CRS(\"+init=epsg:3310\"))\nzoi <- st_transform(zoi, crs=3310)\nobs.gis[, `:=`(\n  Lon = st_coordinates(stations)[, \"X\"],\n  Lat = st_coordinates(stations)[, \"Y\"]\n)]\n\n# Covariates\ncovariates <- list(era=era, dem=dem)\nobs.meta <- obs.gis[StationNbr %in% names(obs.ts), .(StationNbr, Lon, Lat)]\n\n# RFmerge\ndir.create(\"./out/2017_RFmerge_proj\")\nmc.cores <- parallel::detectCores()-2\n\nrfmep <- RFmerge(\n  x = obs.ts, \n  metadata = obs.meta, \n  cov = covariates, \n  id=\"StationNbr\", lat=\"Lat\", lon=\"Lon\", ED=TRUE,\n  mask=zoi, training=0.9, write2disk=TRUE, drty.out=\"./out/2017_RFmerge_proj\",\n  parallel=\"parallel\", par.nnodes=mc.cores)\n\nnames(rfmep)[c(1:2, nlayers(rfmep))]\n# [1] \"X2017.01.01.01.00.00\" \"X2017.01.01.02.00.00\" \"X2017.05.01.00.00.00\"\n\ncrs(rfmep)\n\n\n\nExtract recalibrated time-series across almond production sites.\n\n\n# Extract recalibrated time-series across production sites\nremoveTmpFiles(h=0)\ndt.imp <- extract(rfmep, pts)\ndt.imp = as.data.table(dt.imp, keep.rownames=TRUE)\ndt.imp[, loc_id := pts$loc_id]\ndt.imp = melt(dt.imp, id.vars=\"loc_id\", variable.name=\"time\", value.name=\"value\", variable.factor=F)\ndt.imp[, time := as.POSIXct(time, format=\"X%Y.%m.%d.%H.%M.%OS\", tz=\"America/Los_Angeles\")]\n\ndt.imp[, range(time)]\ndt.imp[, `:=`(\n  # Convert to IDate\n  date = as.IDate(time),\n  time = as.ITime(time)\n)]\n\n# Re-extract ERA5-LAND over period to double-check\nr <- brick(f[1], quick=T)\npts <- spTransform(pts, crs(r))\ndt.era <- lapply(f, function(x) {\n  r = brick(x, quick=T)\n  y = extract(r, pts)\n  y = as.data.table(y, keep.rownames=TRUE)\n  y[, loc_id := pts$loc_id]\n  y = melt(y, id.vars=\"loc_id\", variable.name=\"time\", value.name=\"value\", variable.factor=F)\n  y[, time := as.POSIXct(time, format=\"X%Y.%m.%d.%H.%M.%OS\", tz=\"UTC\")]\n})\ndt.era <- rbindlist(dt.era)\ndt.era[, range(time)]\ndt.era[, `:=`(\n  # Convert to IDate\n  date = as.IDate(time),\n  time = as.ITime(time)\n)]\n\n# Impute ERA5 hourly time-series with output of RFmerge\ndt <- readRDS(file.path(dir, \"./tmp/2020-tmean-hourly_olam_ca_almd.rds\"))\ndt.imp[dt, on=.(loc_id, date, time), era := i.value\n][dt.era, on=.(loc_id, date, time), era_valid := i.value]\n\n# Save\ndt <- dt[!dt.imp, on=.(loc_id, date, time)]\ndt <- rbind(dt, dt.imp[, .SD, .SDcols=names(dt)])\nsetorder(dt, loc_id, date, time)\nsaveRDS(dt, file.path(dir, \"./tmp/2020-tmean-hourly_olam_ca_almd_imputed.rds\"))\n\n\n\n\n\nrm(x, i, j, t, tmp, dem1, dem2, dem3, dem4, n, x1, x2, dt, dtc)\nsave.image(file.path(dir, \"./tmp/2020-burn_olam_usa_06.RData\"))\n\n\n\nValidate ZOI, DEM, and ERA5 covariates.\n\n\nera <- brick(\"./out/ERA5_2m_temperature_2017.grd\")\nera <- raster(era, 1)\n\ntmap_mode(\"view\")\ntm_shape(era) + \n  tm_raster(title=\"ERA5-LAND<br/>Temperature<br/>2020-02-01 00:00<br/>°C\", alpha=.6) +\n  tm_shape(stations) + tm_dots(\"black\", title=\"CIMIS WS\") + \n  tm_shape(pts) + tm_dots(\"blue\", title=\"OLAM Site\") + \n  tm_shape(pts[pts$loc_id %in% c(25, 82, 83), ]) + \n  tm_dots(\"red\")\n\n\n\n\nDEM at ERA5 extent and resolution.\n\n\npts <- spTransform(pts, CRS(\"+init=epsg:3310\"))\n\nplot(dem, main=\"SRTM 90m (meter)\",\n  col=terrain.colors(80, alpha=1))\nplot(zoi, add=T, lty=2, col=NA)\nplot(pts, add=T, pch=16)\nplot(stations, add=T, col=pal[c(\"red\", \"green\")][1+(obs.gis$IsActive==\"True\")], pch=\"x\")\nlegend(\"topright\", legend=c(\"Active station\", \"Stale station\", \"Production site\"),\n  col=pal[c(\"red\", \"green\", \"black\")], pch=c(\"x\", \"x\", \"o\"), cex=.8)\n\n\n\n\nCIMIS station observations between Jan-Apr 2017.\n\n\nobs[, .(\n  `Obs.` = comma(.N), \n  `NA` = percent(sum(is.na(Value))/.N), \n  `Min.` = min(Value, na.rm=T), \n  `Max.` = max(Value, na.rm=T),\n  `Date Range` = paste(range(Date, na.rm=T), collapse=\" - \")\n), keyby=.(StationNbr)] %>%\n  paged_table()\n\n\n\n\n\n\n\nplot(obs.ts[,1], col=alpha(pal[1], .7),\n  main=paste(\"Station\", names(obs.ts)[1]), xlab=\"Hourly Temp. °C\", ylab=NA)\ngrid()\n\n\n\nplot(obs.ts[,20], col=alpha(pal[1], .7),\n  main=paste(\"Station\", names(obs.ts)[20]), xlab=\"Hourly Temp. °C\", ylab=NA)\ngrid()\n\n\n\n\n\n\nhistogram(~Value|StationNbr, data=obs, \n  col=alpha(pal[1], .6), border=pal[\"black\"],\n  par.settings=my.settings,\n  layout=c(2,6), xlab=\"Jan-Apr 2017 Hourly Temp. °C\")\n\n\n\n\n\n\nplot(rfmep[[1]], main=\"RF-MEP Temperatures\", xlab=names(rfmep)[1],\n  col=terrain.colors(80, alpha=1))\nplot(pts, pch=16, col=pal[\"black\"], add=T)\nplot(stations[stations$StationNbr %in% names(obs.ts),], pch=\"x\", col=pal[\"black\"], add=T)\nlegend(\"topright\", legend=c(\"Active station\", \"Production site\"), pch=c(\"x\", \"o\"), cex=.8)\n\n\n\n\n\n\nplot(era[[1]], main=\"ERA5-LAND Temperatures\", xlab=names(era)[1],\n  col=terrain.colors(80, alpha=1))\nplot(pts, pch=16, col=pal[\"black\"], add=T)\nplot(stations[stations$StationNbr %in% names(obs.ts),], pch=\"x\", col=pal[\"black\"], add=T)\nlegend(\"topright\", legend=c(\"Active station\", \"Production site\"), pch=c(\"x\", \"o\"), cex=.8)\n\n\n\n\nHourly time-series from CIMIS ground stations:\n\n\nwireframe(Value~as.numeric(Date)*Time, data=obs, \n  xlab=\"Date\", ylab=\"Hour\", sub=\"CIMIS Stations - Hourly Temp. °C\",\n  col=NA, col.regions=terrain.colors(100, alpha=.4), drape=T,\n  at=do.breaks(c(-5,35), 100)\n)\n\n\n\n\nCompared to hourly time-series at production sites from ERA5-LAND:\n\n\nwireframe(era~as.numeric(date)*time, data=dt.imp, \n  xlab=\"Date\", ylab=\"Hour\", zlab=\"°C\",  \n  sub=\"Production Sites - Hourly Temp. °C (ERA5-LAND)\",\n  col=NA, col.regions=terrain.colors(100, alpha=.4), drape=T,\n  at=do.breaks(c(-5,30), 100)\n)\n\n\n\n\nMean recalibration effect across production sites (after RFmerge):\n\n\nwireframe((value-era)~as.numeric(date)*time, data=dt.imp, \n  xlab=\"Date\", ylab=\"Hour\", zlab=\"°C\",  \n  sub=\"ERA5-LAND Mean Recalibration Effect\\nacross Production Sites\\nHourly Temp. °C\",\n  col=NA, col.regions=terrain.colors(100, alpha=.4), drape=T\n)\n\n\n\n\nFDD index across sites between Feb-01 and Mar-31, 2017 (before and after ground calibration):\n\n\ndt.imp[date %between% c(\"2017-02-01\", \"2017-03-31\"), .(\n  era = min(era, na.rm=T),\n  era_valid = min(era_valid, na.rm=T),\n  value = min(value, na.rm=T)\n), by=.(loc_id, date)][, .(\n  `FDD (before)` = sum(fifelse(era<0, pmax(era, -4, na.rm=T), 0), na.rm=T),\n  `FDD (validate)` = sum(fifelse(era_valid<0, pmax(era_valid, -4, na.rm=T), 0), na.rm=T),\n  `FDD (after)` = sum(fifelse(value<0, pmax(value, -4, na.rm=T), 0), na.rm=T)\n), keyby=.(loc_id)]%>%\n  paged_table()\n\n\n\n\n\n\nSee Baez-Villanueva, O. M., Zambrano-Bigiarini, M., Diego, J., Osorio, G.-, & Mcnamara, I. (2020). Tutorial for merging satellite-based precipitation datasets with ground observations using RFmerge.↩︎\n\n  \n    \n      Share:  \n      \n        \n      \n      \n        \n      \n    \n  \n\n\n",
    "preview": "posts/2021-01-16-rfmerge/index_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2023-12-13T22:24:48+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-12-02-era5-ca/",
    "title": "ERA5-LAND Temperature Validation (California)",
    "description": "Can we justify winter Y2017 corrections to ERA5-LAND temperature grids over central California?",
    "author": [
      {
        "name": "BACOU, Melanie",
        "url": "https://linkedin/in/mbacou"
      }
    ],
    "date": "2020-12-02",
    "categories": [
      "risk modeling"
    ],
    "contents": "\n\nContents\nResults\nTemperature Minima\nFrost Index\n\nCan we justify Y2017 correction to ERA5 grids over OLAM portfolio?\nPortfolio-wide ERA5-LAND temperature validation against NOAA GHCN ground records\n\n\nlibrary(knitr)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(raster)\nlibrary(scales)\nlibrary(data.table)\nlibrary(zoo)\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(rnoaa)\n\ndir <- \".\"\nload(file.path(dir, \"./tmp/2020-burn_olam_usa_07.RData\"))\n\n\n\n\n\n# Clear workspace, keep portfolio details\nload(file.path(dir, \"./tmp/2020-burn_olam_usa_06.RData\"))\nrm(list=setdiff(ls(), c(\"dir\", \"pts.dt\", \"dt.era\", \"dt.imp\")))\n\npts <- SpatialPointsDataFrame(pts.dt[, .(X,Y)], data.frame(pts.dt), \n  proj4string=CRS(\"+init=epsg:4326\"))\n\n\n\n\n\n# Get GHCN ground obs across ZOI\nstations <- ghcnd_stations()\nsetDT(stations)\nvars <- c(\"PRCP\", \"TAVG\", \"TMAX\", \"TMIN\")\nstations[element %in% vars, .N, by=element]\nstations <- stations[state==\"CA\" & element %in% vars]\n\n# Convert to spatial\nstations.sp <- SpatialPointsDataFrame(stations[, .(longitude, latitude)], stations,\n  proj4string=CRS(\"+init=epsg:4326\"))\n\n# Keep only stations within 30 km of any OLAM site\npts <- spTransform(pts, CRS(\"+init=epsg:3310\"))\nstations.sp <- spTransform(stations.sp, CRS(\"+init=epsg:3310\"))\ndist <- rgeos::gWithinDistance(stations.sp, pts, dist=30*1000, byid=TRUE)\ndist <- colSums(dist)\nnames(dist) <- stations.sp$id\ndist <- dist[dist>0]\nids <- names(dist)\n\npts <- spTransform(pts, CRS(\"+init=epsg:4326\"))\nstations.sp <- spTransform(stations.sp, CRS(\"+init=epsg:4326\"))\n\nplot(extent(pts), lty=2, col=NA, xlab=NA, ylab=NA)\nplot(stations.sp[stations.sp$id %in% ids,], col=\"black\", add=T)\nplot(pts, col=\"blue\", pch=\"*\", add=T)\n\nids <- stations[id %in% ids & element %in% vars & last_year > 2009, unique(id)]\nstations[id %in% ids & element %in% vars]\n\n# Get daily station time-series for the 29 selected\n# Request seems to time out when too large so batch it\nstations.dt <- lapply(ids, function(x) \n  try(ghcnd_search(x, var=vars, date_min=\"2010-01-01\", refresh=T)))\nstations.dt <- stations.dt[sapply(stations.dt, function(x) class(x)!=\"try-error\")]\nstations.dt <- do.call(c, stations.dt)\nstations.dt <- lapply(stations.dt, function(x) setnames(x, 2, \"value\"))\nstations.dt <- rbindlist(stations.dt, idcol=\"var\")\n\nstations.dt[, .N, by=var]\npar(mfrow=c(2,2))\nfor(i in stations.dt[, unique(var)]) stations.dt[var==i, hist(value, main=i)]\npar(mfrow=c(1,1))\n\n# Convert tenths of degrees Celsius to °C\nstations.dt[, value := as.numeric(value)\n][var %in% tolower(vars[2:4]), value := value/10]\n\nids <- stations.dt[, unique(id)]\n\n\n\n\n\n# Extract ERA5 at stations' coordinates\nx <- c(\"2010-01-01\", \"2020-07-31\")\ncat <- wc_catalog(x, code=\"era5_temp_h_usa_ca\")\ndt <- wc_extract(\n  stations[id %in% ids, .N, by=.(loc_id=id, X=longitude, Y=latitude)][, N:=NULL], \n  catalog=cat)\n\n# Verify sequence\ndt[c(1, .N), .(date, time)]\ndt[, .N, by=.(y=year(date), loc_id)][N!=8760 & N!=8784 & N!=5112]\n# => OK\n\ndt[,\n  # Apply timezone\n  time := with_tz(as.POSIXct(paste(date, time, sep=\" \")), tzone=\"America/Los_Angeles\")\n][, `:=`(\n  # Convert to IDate\n  date = as.IDate(time),\n  time = as.ITime(time)\n)]\n\n# Verify\ndt[c(1, .N), .(date, time)]\ndt[, .N, by=loc_id][, uniqueN(N)]\ndt[, hist(value)]\ndt[, summary(value)]\n#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n# -6.623  10.852  17.053  17.939  24.544  43.893  \n\n# Daily\ndt <- dt[, .(\n  Tmean = mean(value, na.rm=T),\n  Tmin = min(value, na.rm=T),\n  Tmax = max(value, na.rm=T)\n), keyby=.(loc_id, date)]\n\n# Combine with GHCN\ntmp <- dcast(stations.dt, id+date~var, value.var=\"value\")\ndt[tmp, on=.(loc_id=id, date=date), `:=`(\n  GHCN_Tmean = i.tavg,\n  GHCN_Tmin = i.tmin,\n  GHCN_Tmax = i.tmax\n)]\n\n\n\n\n\nrm(x, i, j, t, tmp)\nsave.image(file.path(dir, \"./tmp/2020-burn_olam_usa_07.RData\"))\n\n\n\nResults\n10-year comparisons between ERA5-LAND and GHCN station network over Feb-March risk period. 11 stations (under 30-km from production sites and with daily temperature records after 2010) are selected for the comparison.\n\n\nplot(cat[date==\"2020-02-01\", crop(raster(file, 1), stations.sp[stations.sp$id %in% ids,])], \n  xlab=NA, ylab=NA, main=\"Tmean °C\", sub=\"ERA5 2020-02-01 00:00\")\nplot(crop(stations.sp[!stations.sp$id %in% ids,], pts), col=\"black\", add=T)\nplot(stations.sp[stations.sp$id %in% ids,], col=\"red\", add=T)\nplot(pts, col=\"blue\", pch=\"*\", add=T)\nplot(pts[pts$loc_id==25,], col=\"blue\", pch=1, cex=2, add=T)\nlegend(\"bottomleft\", \n  legend=c(\"GHCN station\", \"GHCN station ≤ 30-km\", \"OLAM production site\", \"Main site\"),\n  col=c(\"black\", \"red\", \"blue\", \"blue\"), pch=c(\"+\", \"+\", \"*\", \"o\"), cex=.7)\n\n\n\n\nList of GHCN stations retained in the analysis.\n\n\nkable(stations[id %in% ids & element %in% c(\"TMIN\", \"TAVG\"), .(\n  first_year, last_year\n), keyby=.(id, name, element)]\n)\n\n\nid\nname\nelement\nfirst_year\nlast_year\nUSC00040444\nBAKERSFIELD 5 NW\nTMIN\n1999\n2020\nUSC00045233\nMADERA\nTMIN\n1928\n2020\nUSC00045532\nMERCED\nTMIN\n1899\n2020\nUSC00048122\nSHAFTER 6E\nTMIN\n2009\n2020\nUSC00048752\nTAFT\nTMIN\n1994\n2011\nUSR0000CCAT\nCATHEYS VALLEY CALIFORNIA\nTAVG\n1999\n2020\nUSR0000CCAT\nCATHEYS VALLEY CALIFORNIA\nTMIN\n1999\n2020\nUSR0000CGSP\nGREEN SPRING CALIFORNIA\nTAVG\n1990\n2020\nUSR0000CGSP\nGREEN SPRING CALIFORNIA\nTMIN\n1990\n2020\nUSW00023155\nBAKERSFIELD AP\nTAVG\n1998\n2020\nUSW00023155\nBAKERSFIELD AP\nTMIN\n1937\n2020\nUSW00023257\nMERCED MUNI AP\nTAVG\n1998\n2005\nUSW00023257\nMERCED MUNI AP\nTMIN\n1998\n2020\nUSW00023258\nMODESTO CITY CO AP\nTAVG\n1998\n2005\nUSW00023258\nMODESTO CITY CO AP\nTMIN\n1927\n2020\nUSW00093242\nMADERA MUNI AP\nTAVG\n1998\n2005\nUSW00093242\nMADERA MUNI AP\nTMIN\n1998\n2020\n\n10-year summary.\n\n\npar(mfrow=c(2,2))\nfor(i in stations.dt[, unique(var)]) stations.dt[var==i, hist(value, main=i)]\n\n\n\n\nTemperature Minima\n2010-2014\n\n\nprd <- c(\"2020-02-01\", \"2020-03-31\")\ndt[, sdate := as.Date(date)][, year := year(date)]\nyear(dt$sdate) <- 2020\n\ntmp <- dt[yday(date) %between% yday(prd), .(\n  Tmin = mean(Tmin, na.rm=T),\n  GHCN_Tmin = mean(GHCN_Tmin, na.rm=T),\n  diff_Tmean = mean(Tmean - GHCN_Tmean, na.rm=T),\n  diff_Tmin = mean(Tmin - GHCN_Tmin, na.rm=T)\n), by=.(year, date, sdate)\n][, sign := diff_Tmin > 0]\n\nggplot(tmp[year(date) %between% c(2010, 2014)], aes(x=sdate)) +\n  geom_line(aes(y=Tmin, color=\"ERA5 Tmin\")) + \n  geom_point(aes(y=Tmin, color=\"ERA5 Tmin\"), size=.5) +\n  geom_line(aes(y=GHCN_Tmin, color=\"GHCN Tmin\")) + \n  geom_point(aes(y=GHCN_Tmin, color=\"GHCN Tmin\"), size=.5) +\n  scale_x_date(date_labels=\"%b-%d\", breaks=\"2 days\") +\n  scale_color_discrete(NULL) +\n  facet_wrap(\"year\", ncol=1) +\n  xlab(NULL) +\n  ggtitle(\"Temperature Mean of Min -- ERA5 vs. GHCN (19 WS)\") +\n  theme(\n    legend.position=\"top\", legend.justification=0, \n    axis.text.x=element_text(angle=-90)\n  )\n\n\n\n\n2015-2020\n\n\nggplot(tmp[year(date) > 2014], aes(x=sdate)) +\n  geom_line(aes(y=Tmin, color=\"ERA5 Tmin\")) + \n  geom_point(aes(y=Tmin, color=\"ERA5 Tmin\"), size=.5) +\n  geom_line(aes(y=GHCN_Tmin, color=\"GHCN Tmin\")) + \n  geom_point(aes(y=GHCN_Tmin, color=\"GHCN Tmin\"), size=.5) +\n  scale_x_date(date_labels=\"%b-%d\", breaks=\"2 days\") +\n  scale_color_discrete(NULL) +\n  facet_wrap(\"year\", ncol=1) +\n  xlab(NULL) +\n  ggtitle(\"Temperature Mean of Min -- ERA5 vs. GHCN (19 WS)\") +\n  theme(\n    legend.position=\"top\", legend.justification=0, \n    axis.text.x=element_text(angle=-90)\n  )\n\n\n\n\n2010-2014\n\n\nggplot(tmp[year(date) %between% c(2010, 2014)], \n  aes(sdate, color=sign)) +\n  geom_segment(aes(xend=sdate, y=Tmin, yend=GHCN_Tmin), size=.8, lineend=\"butt\") +\n  geom_point(aes(y=GHCN_Tmin)) +\n  scale_x_date(date_labels=\"%b-%d\", breaks=\"3 day\") +\n  scale_color_discrete(NULL, labels=c(\"ERA5 ≤ GHCN\", \"ERA5 > GHCN\")) +\n  facet_wrap(\"year\", ncol=1) +\n  xlab(NULL) +\n  ggtitle(\"Temperature Mean of Min -- ERA5 vs. GHCN WS\") +\n  theme(\n    legend.position=\"top\", legend.justification=0, \n    axis.text.x=element_text(angle=-90)\n  )\n\n\n\n\n2015-2020\n\n\nggplot(tmp[year(date) > 2014], \n  aes(sdate, color=sign)) +\n  geom_segment(aes(xend=sdate, y=Tmin, yend=GHCN_Tmin), size=.8, lineend=\"butt\") +\n  geom_point(aes(y=GHCN_Tmin)) +\n  scale_x_date(date_labels=\"%b-%d\", breaks=\"3 day\") +\n  scale_color_discrete(NULL, labels=c(\"ERA5 ≤ GHCN\", \"ERA5 > GHCN\")) +\n  facet_wrap(\"year\", ncol=1) +\n  xlab(NULL) +\n  ggtitle(\"Temperature Mean of Min -- ERA5 vs. GHCN WS\") +\n  theme(\n    legend.position=\"top\", legend.justification=0, \n    axis.text.x=element_text(angle=-90)\n  )\n\n\n\n\nDifferences between ERA5 Tmin and GHCN Tmin over risk period:\n\n\ndt[yday(date) %in% yday(prd), summary(Tmin - GHCN_Tmin)]\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-5.9080 -1.1880  0.2500  0.2953  1.5979  9.7133     206 \n\nDifferences between ERA5 Tmin and GHCN Tmin over risk period (GHCN below 0°C):\n\n\ndt[yday(date) %in% yday(prd) & GHCN_Tmin <= 0, summary(Tmin - GHCN_Tmin)]\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.364   1.822   2.350   2.058   2.350   2.405 \n\nDifferences between ERA5 Tmean and GHCN Tmean over risk period:\n\n\ndt[yday(date) %in% yday(prd), summary(Tmean - GHCN_Tmean)]\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-4.5485 -1.7915 -1.1321 -0.9827 -0.1575  1.9854     359 \n\nDifferences between ERA5 Tmax and GHCN Tmax over risk period:\n\n\ndt[yday(date) %in% yday(prd), summary(Tmax - GHCN_Tmax)]\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-4.6174 -1.4994 -0.6568 -0.6119  0.1649  4.7969     204 \n\nCorrelation summary on temperature minima (all available dates):\n\n\ntmp <- dt[!is.na(GHCN_Tmin), .(cor = cor(GHCN_Tmin, Tmin, method=\"pearson\"))]\nsummary(tmp$cor)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.9258  0.9258  0.9258  0.9258  0.9258  0.9258 \n\nCorrelation summary on temperature minima (GHCN below 0°C, all available dates):\n\n\ntmp <- dt[!is.na(GHCN_Tmin) & GHCN_Tmin <= 0, .(cor = cor(GHCN_Tmin, Tmin, method=\"pearson\"))]\nsummary(tmp$cor)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2952  0.2952  0.2952  0.2952  0.2952  0.2952 \n\nERA5 bias along GHCN ground temperatures:\n\n\ntmp <- dt[!is.na(GHCN_Tmin), .(\n  GHCN_Tmean, GHCN_Tmin, \n  Tmean_bias = GHCN_Tmean - Tmean,\n  Tmin_bias = GHCN_Tmin - Tmin\n)]\n\nggplot(tmp) +\n  geom_smooth(aes(x=GHCN_Tmean, y=Tmean_bias, color=\"Bias (Tmean)\")) +\n  geom_smooth(aes(x=GHCN_Tmin, y=Tmin_bias, color=\"Bias (Tmin)\")) +\n  geom_hline(aes(yintercept=0), color=\"black\", linetype=1) +\n  geom_vline(aes(xintercept=0), color=\"black\", linetype=3) +\n  scale_color_discrete(NULL) +\n  scale_x_continuous(n.breaks=10) +\n  scale_y_continuous(n.breaks=10) +\n  xlab(\"GHCN Temp. (°C)\") + ylab(\"ERA5 Bias (°C)\") +\n  ggtitle(\"ERA5 Bias vs. GHCN WS (2010-2020)\") +\n  theme(\n    legend.position=\"top\", legend.justification=0\n  )\n\n\n\n\nFrost Index\n\n\ndegree_frost <- c(-4, 0)\n\n# Add daily index values\nsetorder(dt, loc_id, date)\nidx <- dt[yday(date) %between% yday(prd), .(\n  idx = sum(degree_frost[2] - pmin(\n    fifelse(Tmin < degree_frost[1], degree_frost[1], Tmin), degree_frost[2]), na.rm=T),\n  idx_ghcn = sum(degree_frost[2] - pmin(\n    fifelse(GHCN_Tmin < degree_frost[1], degree_frost[1], GHCN_Tmin), degree_frost[2]), na.rm=T)\n), by=.(loc_id, year)]\n\n\n\n\n\ntmp <- melt(idx, id.vars=c(\"loc_id\", \"year\"))\ntmp <- tmp[, .(value=mean(value, na.rm=T)), by=.(year, variable)]\n\nggplot(tmp[variable %in% c(\"idx\", \"idx_ghcn\")], \n  aes(year, value, fill=variable)) +\n  geom_col(position=\"dodge\", color=NA, alpha=.8, width=.8) +\n  scale_fill_discrete(NULL, labels=c(\"GHCN FDD\", \"ERA5 FDD\")) +\n  scale_x_continuous(breaks=2010:2020) +\n  xlab(NULL) + ylab(NULL) +\n  ggtitle(\"Mean FDD across Stations -- ERA5 vs. GHCN (2010-2020)\") +\n  theme(\n    axis.text.x=element_text(angle=-90),\n    legend.position=\"top\", legend.justification=0\n  )\n\n\n\n\n\n\nggplot(idx[idx_ghcn>0], aes(idx_ghcn, idx)) +\n  geom_abline(linetype=3) +\n  geom_smooth(aes(color=\"ERA5 non-adjusted\")) +\n  geom_point(shape=\"+\", size=4) +\n  scale_color_discrete(NULL) +\n  xlab(\"GHCN FDD\") + ylab(\"ERA5 FDD\") +\n  ggtitle(\"FDD -- ERA5 vs. GHCN (2010-2020)\") +\n  theme(\n    legend.position=\"top\", legend.justification=0\n  )\n\n\n\n\n\n\n\n  \n    \n      Share:  \n      \n        \n      \n      \n        \n      \n    \n  \n\n\n",
    "preview": "posts/2020-12-02-era5-ca/index_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2023-12-13T22:24:47+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 1152
  }
]
